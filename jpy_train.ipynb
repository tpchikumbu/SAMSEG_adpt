{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253.36s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.24.1\n",
      "  Downloading numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.10.0.84)\n",
      "Requirement already satisfied: torch in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.9.2)\n",
      "Requirement already satisfied: monai in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: nibabel in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: scikit-image in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.24.0)\n",
      "Requirement already satisfied: synapseclient in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (4.4.1)\n",
      "Requirement already satisfied: safetensors in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: PyYAML in /home/peter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
      "Requirement already satisfied: fsspec in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2024.9.0)\n",
      "Requirement already satisfied: jinja2 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (9.1.0.70)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (1.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.15.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/peter/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/peter/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 3)) (12.6.68)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/peter/.local/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 4)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/peter/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.53.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/peter/.local/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/peter/.local/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/peter/.local/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /home/peter/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (2.35.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/peter/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (0.4)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/peter/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.21.0 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http~=1.21.0 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.21.0)\n",
      "Requirement already satisfied: async-lru~=2.0.4 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: nest-asyncio~=1.6.0 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.6.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66.2 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (4.66.5)\n",
      "Requirement already satisfied: httpx~=0.27.0 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (0.27.2)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.18 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.26.20)\n",
      "Requirement already satisfied: opentelemetry-api~=1.21.0 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.21.0)\n",
      "Requirement already satisfied: psutil~=5.9.8 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (5.9.8)\n",
      "Requirement already satisfied: asyncio-atexit~=1.0.1 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.22.0 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (2.32.3)\n",
      "Requirement already satisfied: deprecated<2.0,>=1.2.4 in /home/peter/.local/lib/python3.10/site-packages (from synapseclient->-r requirements.txt (line 10)) (1.2.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/peter/.local/lib/python3.10/site-packages (from deprecated<2.0,>=1.2.4->synapseclient->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/peter/.local/lib/python3.10/site-packages (from httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (1.0.5)\n",
      "Requirement already satisfied: certifi in /home/peter/.local/lib/python3.10/site-packages (from httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (2024.8.30)\n",
      "Requirement already satisfied: sniffio in /home/peter/.local/lib/python3.10/site-packages (from httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: anyio in /home/peter/.local/lib/python3.10/site-packages (from httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (4.4.0)\n",
      "Requirement already satisfied: idna in /home/peter/.local/lib/python3.10/site-packages (from httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (3.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/peter/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-api~=1.21.0->synapseclient->-r requirements.txt (line 10)) (6.11.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.21.0->synapseclient->-r requirements.txt (line 10)) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.21.0->synapseclient->-r requirements.txt (line 10)) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.21.0->synapseclient->-r requirements.txt (line 10)) (1.21.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http~=1.21.0->synapseclient->-r requirements.txt (line 10)) (1.65.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-proto==1.21.0->opentelemetry-exporter-otlp-proto-http~=1.21.0->synapseclient->-r requirements.txt (line 10)) (4.25.4)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /home/peter/.local/lib/python3.10/site-packages (from opentelemetry-sdk~=1.21.0->synapseclient->-r requirements.txt (line 10)) (0.42b0)\n",
      "Requirement already satisfied: six>=1.5 in /home/peter/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/peter/.local/lib/python3.10/site-packages (from requests<3.0,>=2.22.0->synapseclient->-r requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/peter/.local/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/peter/.local/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/peter/.local/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api~=1.21.0->synapseclient->-r requirements.txt (line 10)) (3.20.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/peter/.local/lib/python3.10/site-packages (from anyio->httpx~=0.27.0->synapseclient->-r requirements.txt (line 10)) (1.2.2)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.0\n",
      "    Uninstalling numpy-1.24.0:\n",
      "      Successfully uninstalled numpy-1.24.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.38.1 requires urllib3~=2.0, but you have urllib3 1.26.20 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import monai\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import threshold, normalize\n",
    "import src.utils as utils\n",
    "\n",
    "from src.brats_dataset import BratsDataset, collate_fn\n",
    "from src.brats_processor import Samprocessor, find_slices\n",
    "\n",
    "\n",
    "from src.segment_anything import build_sam_vit_b, SamPredictor\n",
    "from src.lora import LoRA_sam\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file\n",
    "with open(\"./config.yaml\", \"r\") as ymlfile:\n",
    "   config_file = yaml.load(ymlfile, Loader=yaml.Loader)\n",
    "\n",
    "# Take dataset path\n",
    "train_dataset_path = \"/home/peter/Documents/Code/samseg/src/testSamples/MEDIUM_Samples\"\n",
    "valid_dataset_path = \"/home/peter/Documents/Code/samseg/src/testSamples/MEDIUM_Samples\"\n",
    "\n",
    "# Setup output directories\n",
    "out_dir = \"./train-out\"\n",
    "\n",
    "latest_ckpt_path = os.path.join(out_dir, 'latest_ckpt.pth.tar')\n",
    "training_loss_path = os.path.join(out_dir, 'training_loss.csv')\n",
    "backup_ckpts_dir = os.path.join(out_dir, 'backup_ckpts')\n",
    "if not os.path.exists(backup_ckpts_dir):\n",
    "    os.makedirs(backup_ckpts_dir)\n",
    "    os.system(f'chmod a+rwx {backup_ckpts_dir}')\n",
    "\n",
    "# Load SAM and create LoRA model\n",
    "sam = build_sam_vit_b(checkpoint=config_file[\"SAM\"][\"CHECKPOINT\"])\n",
    "sam_lora = LoRA_sam(sam, config_file[\"SAM\"][\"RANK\"])\n",
    "model = sam_lora.sam\n",
    "\n",
    "# Process the datasets\n",
    "processor = Samprocessor(model)\n",
    "train_ds = BratsDataset(train_dataset_path, \"train\")\n",
    "valid_ds = BratsDataset(valid_dataset_path, \"train\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_ds, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer and Loss\n",
    "optimizer = Adam(model.image_encoder.parameters(), lr=1e-4, weight_decay=0)\n",
    "seg_loss = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')\n",
    "num_epochs = config_file[\"TRAIN\"][\"NUM_EPOCHS\"]\n",
    "\n",
    "loss_functions = [nn.MSELoss(), nn.CrossEntropyLoss()]\n",
    "loss_weights = [0.4, 0.7]\n",
    "backup_interval = 5\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS-MEN-00133-000:\n",
      "Loss: <map object at 0x7f55e3947370>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [02:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m [processor(image, batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m], idx)]\n\u001b[0;32m---> 21\u001b[0m   chunked_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;66;03m#chunked_outputs.requires_grad_(True)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m   outputs\u001b[38;5;241m.\u001b[39mextend(chunked_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/SAMSEG_adpt/src/segment_anything/modeling/sam.py:96\u001b[0m, in \u001b[0;36mSam.forward\u001b[0;34m(self, batched_input, multimask_output)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mPredicts masks end-to-end from provided images and prompts.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mIf prompts are not known in advance, using SamPredictor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        to subsequent iterations of prediction.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m input_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batched_input], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m image_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_record, curr_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batched_input, image_embeddings):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/SAMSEG_adpt/src/segment_anything/modeling/image_encoder.py:111\u001b[0m, in \u001b[0;36mImageEncoderViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/SAMSEG_adpt/src/segment_anything/modeling/image_encoder.py:173\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    171\u001b[0m     x, pad_hw \u001b[38;5;241m=\u001b[39m window_partition(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[0;32m--> 173\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Reverse window partition\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/SAMSEG_adpt/src/segment_anything/modeling/image_encoder.py:230\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# q, k, v with shape (B * nHead, H * W, C)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, B \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H \u001b[38;5;241m*\u001b[39m W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 230\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rel_pos:\n\u001b[1;32m    233\u001b[0m     attn \u001b[38;5;241m=\u001b[39m add_decomposed_rel_pos(attn, q, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_pos_h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_pos_w, (H, W), (H, W))\n",
      "File \u001b[0;32m~/Documents/Code/SAMSEG_adpt/src/segment_anything/modeling/image_encoder.py:230\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# q, k, v with shape (B * nHead, H * W, C)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, B \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H \u001b[38;5;241m*\u001b[39m W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 230\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rel_pos:\n\u001b[1;32m    233\u001b[0m     attn \u001b[38;5;241m=\u001b[39m add_decomposed_rel_pos(attn, q, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_pos_h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_pos_w, (H, W), (H, W))\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1600\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1834\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "      torch.cuda.empty_cache()\n",
    "      # print(f\"{batch[0][0]}:\")\n",
    "      \n",
    "      slice_idx = find_slices((batch[0][2] > 0).float())\n",
    "      batch_loss = []\n",
    "      for idx in slice_idx:\n",
    "        \n",
    "        outputs = []\n",
    "        #with torch.no_grad():\n",
    "        for image in batch[0][1]:\n",
    "          input = [processor(image, batch[0][2], idx)]\n",
    "          chunked_outputs = model(batched_input=input,\n",
    "                        multimask_output=False)\n",
    "          #chunked_outputs.requires_grad_(True)\n",
    "          outputs.extend(chunked_outputs)\n",
    "          del chunked_outputs\n",
    "        stk_gt, stk_out = utils.stacking_batch(input, outputs)\n",
    "        stk_out = stk_out.squeeze(1)\n",
    "        # stk_gt = stk_gt.unsqueeze(1) # We need to get the [B, C, H, W] starting from [H, W]\n",
    "        \n",
    "        # Apply loss function to each scan type and calculate the average\n",
    "        # dumb_loss = []\n",
    "        # for i in range(stk_out.shape[0]):\n",
    "        #   loss_one = seg_loss(stk_out[i], stk_gt.float().to(device))\n",
    "        #   dumb_loss.append(loss_one)\n",
    "        # loss_avg = torch.mean(torch.stack(dumb_loss))\n",
    "        # print(f\"Loss (avg): {loss_avg}\")\n",
    "\n",
    "        # Loss calculation with map function\n",
    "        stk_gt = stk_gt.unsqueeze(1) # We need to get the [B, C, H, W] starting from [H, W]\n",
    "        stk_gt = stk_gt.repeat(4, 1, 1, 1)\n",
    "        loss = map(seg_loss, stk_out, stk_gt.float().to(device))\n",
    "        loss_list = list(loss) # Convert map object to list\n",
    "        loss_avg = torch.mean(torch.stack(loss_list)) # Calculate the average loss per scan type\n",
    "\n",
    "        # Optimize parameters with the average loss\n",
    "        optimizer.zero_grad()\n",
    "        loss_avg.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        batch_loss.append(loss_avg)\n",
    "                \n",
    "      img_loss = torch.mean(torch.stack(batch_loss))\n",
    "      # optimizer.zero_grad()\n",
    "      # scan_loss.requires_grad_(True)\n",
    "      # scan_loss.backward()\n",
    "      # # print(\"GRADIENT:   \", scan_loss.grad)\n",
    "      # # optimize\n",
    "      # optimizer.step()\n",
    "      epoch_losses.append(img_loss.item())\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "    print(f'EPOCH: {epoch}; Mean training loss: {mean(epoch_losses)}')\n",
    "    utils.save_tloss_csv(training_loss_path, epoch, mean(epoch_losses))\n",
    "    print(\"Saving checkpoint...\")\n",
    "    checkpoint = {\n",
    "      'epoch': epoch,\n",
    "      'model_sd': model.state_dict(),\n",
    "      'optim_sd': optimizer.state_dict(),\n",
    "      'model': model,\n",
    "      'loss_functions': loss_functions,\n",
    "      'loss_weights': loss_weights,\n",
    "    }\n",
    "    torch.save(checkpoint, latest_ckpt_path)\n",
    "    if epoch % backup_interval == 0:\n",
    "        torch.save(checkpoint, os.path.join(backup_ckpts_dir, f'epoch{epoch}.pth.tar'))\n",
    "    print('Checkpoint saved successfully.')\n",
    "\n",
    "# Save the parameters of the model in safetensors format\n",
    "rank = config_file[\"SAM\"][\"RANK\"]\n",
    "sam_lora.save_lora_parameters(f\"lora_rank{rank}.safetensors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
